{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PatrickTchoupe/HGR-Project/blob/main/gestureRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q2m_n1cUclfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "71VBoyvTZYtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrotSx2NY6q0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self,elements,path=\"drive/MyDrive/Datasets_CSV/Domain1_csv/Subject\"):\n",
        "\n",
        "        self.dataset = [{} for _ in range(10)]\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        for subject in range(1,11):\n",
        "            for i in elements:\n",
        "                self.dataset[subject-1][i] = []\n",
        "                for j in range(1,11):\n",
        "                    try:\n",
        "                        user_data=[]\n",
        "                        df  = pd.read_csv(f\"{path}{subject}-{i}-{j}.csv\")\n",
        "                        for k, line in df.iterrows():\n",
        "                            user_data.append(list(line[0:3]))\n",
        "                        self.dataset[subject-1][i].append(user_data)\n",
        "                        self.data.append(user_data)\n",
        "                        self.labels.append(i)\n",
        "                    except IOError as e:\n",
        "                        print(f\"Unable to read dataset file {path}{subject}-{i}-{j}.csv!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCeLuai1Y6q4"
      },
      "outputs": [],
      "source": [
        "#Domain 1 dataset\n",
        "data1 = Dataset([i for i in range(10)])\n",
        "data1.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#domain 4 dataset\n",
        "figures = [\"Pyramid\",\"Sphere\",\"Cone\",\"Cuboid\",\"Cylinder\",\"Hemisphere\",\"RectangularPipe\",\"Tetrahedron\",\"Toroid\",\"CylindricalPipe\"]\n",
        "data4 = Dataset(figures,\"drive/MyDrive/Datasets_CSV/Domain4_csv/Subject\")"
      ],
      "metadata": {
        "id": "A_8qe5E4Y6q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 : KNN and DTW"
      ],
      "metadata": {
        "collapsed": false,
        "id": "wt9VoHIXY6q7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import mode\n",
        "from joblib import Parallel, delayed\n",
        "from numba import njit, prange\n",
        "from numba.typed import List\n",
        "\n",
        "@njit()\n",
        "def distance(x, y):\n",
        "    \"\"\"\n",
        "    This function computes the euclidean distance between two vectors\n",
        "    \"\"\"\n",
        "    dist = 0.0\n",
        "    for i in range(len(x)):\n",
        "        diff = (x[i] - y[i])\n",
        "        dist += diff * diff\n",
        "    return dist\n",
        "\n",
        "@njit(nogil=True)\n",
        "def dtw_distance(time_serie1, time_serie2):\n",
        "    \"\"\"\n",
        "    This function computes the DTW distance\n",
        "    \"\"\"\n",
        "    l1, l2 = len(time_serie1), len(time_serie2)\n",
        "    cost_matrix = np.full((l1 + 1, l2 + 1), np.inf)\n",
        "    # Initialize the first cell\n",
        "    cost_matrix[0, 0] = 0.\n",
        "    # populatte the cost matrix\n",
        "    for i in range(l1):\n",
        "        for j in range(l2):\n",
        "            cost_matrix[i+1, j+1] = distance(List(time_serie1[i]), List(time_serie2[j]))\n",
        "            cost_matrix[i+1, j+1] += min(cost_matrix[i, j +1], cost_matrix[i+1, j], cost_matrix[i, j])\n",
        "    cost_matrix = np.sqrt(cost_matrix[1:, 1:]) # to get a matrix form\n",
        "    return cost_matrix[-1, -1]/(l1+l2)\n",
        "\n",
        "class KNN_DTW:\n",
        "    \"\"\"\n",
        "    This class is a classifier using DTW as distance measure between pairs of time series data\n",
        "    \"\"\"\n",
        "    def __init__(self, n_neighbors=1):\n",
        "        self.n_neighbors = n_neighbors\n",
        "\n",
        "    def fit(self, x, labels):\n",
        "        \"\"\"\n",
        "        To fix the training set and the corresponding labels\n",
        "        x: the training set containin list of the sequences\n",
        "        labels: the labels corresponding to each sequences in x\n",
        "        \"\"\"\n",
        "        self.x = np.array(x)\n",
        "        self.labels = np.array(labels)\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "        To predict the class of the test\n",
        "        \"\"\"\n",
        "        dist_matrix = np.zeros((x.shape[0], self.x.shape[0]))\n",
        "\n",
        "        # compute the distance matrix between the training (self.x) and the test set(x)\n",
        "        matrix = Parallel(n_jobs=-1, prefer=\"threads\", verbose=0)(\n",
        "            delayed(dtw_distance)(\n",
        "                List(x[i]), List(self.x[j])\n",
        "            )\n",
        "            for i in range(len(x)) for j in range(len(self.x))\n",
        "        )\n",
        "        dist_matrix = np.array(matrix).reshape((len(x), -1))\n",
        "        # the index of the k nearest neighbors\n",
        "        indexes = dist_matrix.argsort()[:, :self.n_neighbors]\n",
        "        # identifiers the labels of neighbors\n",
        "        labels = self.labels[indexes]\n",
        "        # get the majority votes between labels\n",
        "        predictions = mode(labels, axis=1)[0]\n",
        "        #print(predictions)\n",
        "        return predictions\n",
        "\n",
        "# Validation function\n",
        "def test(user_id, dataset, labels, model, LIMIT=100):\n",
        "    # split the dataset\n",
        "    indexes = range(user_id*LIMIT, user_id*LIMIT+LIMIT)\n",
        "    train_set = np.delete(dataset, indexes)\n",
        "    train_labels = np.delete(labels, indexes)\n",
        "    test_labels = labels[indexes]\n",
        "    test_set = dataset[indexes]\n",
        "    # Prediction\n",
        "    model.fit(train_set, train_labels)\n",
        "    predictions = model.predict(test_set)\n",
        "    return accuracy_score(test_labels, predictions), predictions\n",
        "\n",
        "def ud_test(gesture_id,dataset,labels,model):\n",
        "    #split the data\n",
        "    indexes = gesture_id.T.flatten()\n",
        "    train_set = np.delete(dataset, indexes)\n",
        "    train_labels = np.delete(labels, indexes)\n",
        "    test_labels = labels[indexes]\n",
        "    test_set = dataset[indexes]\n",
        "    # Prediction\n",
        "    model.fit(train_set, train_labels)\n",
        "    predictions = model.predict(test_set)\n",
        "    return accuracy_score(test_labels, predictions), predictions\n",
        "\n",
        "\n",
        "def validation(dataset, labels, model, LIMIT=100):\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    accuracies = []\n",
        "    predictions = []\n",
        "    for user_id in range(10):\n",
        "        accuracy, prediction = test(user_id, dataset, labels, model, LIMIT)\n",
        "        accuracies.append(accuracy)\n",
        "        predictions.append(prediction)\n",
        "        print(\"The user score {}: {}\".format(user_id+1, accuracies[-1]))\n",
        "    return accuracies, predictions\n",
        "\n",
        "def ud_validation(dataset,labels,model):\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    accuracies = []\n",
        "    predictions = []\n",
        "    blocs = [[100*i + 10*k + j for i in range(10)] for j in range(10) for k in range(10)]\n",
        "    indexes = np.reshape(blocs, (10, 10, 10))\n",
        "    i=0\n",
        "    for b in indexes:\n",
        "        accuracy, prediction = ud_test(b, dataset, labels, model)\n",
        "        accuracies.append(accuracy)\n",
        "        predictions.append(prediction)\n",
        "        print(\"The sample score {}: {}\".format(i, accuracies[-1]))\n",
        "        i+=1\n",
        "    return accuracies, predictions\n"
      ],
      "metadata": {
        "id": "NR8kJOI9Y6q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Application on domain 1 user-dependent setting"
      ],
      "metadata": {
        "collapsed": false,
        "id": "-eKLD1uDY6rA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model1_ud = KNN_DTW(3)\n",
        "accuracies1_ud, prediction1_ud = ud_validation(np.array(data1.data,dtype=object).T, data1.labels, model1_ud)\n",
        "print(f\"Accuracies {accuracies1_ud} average accuracy {np.mean(accuracies1_ud)} and standard deviation {np.std(accuracies1_ud)}\")"
      ],
      "metadata": {
        "id": "o83JZ9oPY6rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application on domain 1 user-independent setting"
      ],
      "metadata": {
        "collapsed": false,
        "id": "vHEZwt6pY6rB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model1 = KNN_DTW(3)\n",
        "accuracies1, prediction1 = validation(np.array(data1.data,dtype=object).T, data1.labels, model1,100)\n",
        "print(f\"Accuracies {accuracies1} average accuracy {np.mean(accuracies1)} and standard deviation {np.std(accuracies1)}\")"
      ],
      "metadata": {
        "id": "E7JsV1vsY6rC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Application on domain 4 user-dependent setting"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7uZCov-DY6rD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model4_ud = KNN_DTW(3)\n",
        "accuracies4_ud, prediction4_ud = ud_validation(np.array(data4.data,dtype=object).T, data4.labels, model4_ud)\n",
        "print(f\"Accuracies {accuracies4_ud} average accuracy {np.mean(accuracies4_ud)} and standard deviation {np.std(accuracies4_ud)}\")"
      ],
      "metadata": {
        "id": "XOwW0-0NY6rD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application on domain 4 user-independent setting"
      ],
      "metadata": {
        "collapsed": false,
        "id": "SSXS1-O9Y6rE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model4 = KNN_DTW(3)\n",
        "accuracies4, prediction4 = validation(np.array(data4.data,dtype=object).T, data4.labels, model4, 100)\n",
        "print(f\"Accuracies {accuracies4} average accuracy {np.mean(accuracies4)} and standard deviation {np.std(accuracies4)}\")"
      ],
      "metadata": {
        "id": "7Qk0N44iY6rE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "wAJ4v2WkY6rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot the confusion matrix"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ACaiIwwQY6rF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_conf_mat(true_labels, pred_labels, LIMIT=100):\n",
        "    for user_id in range(len(pred_labels)):\n",
        "        print(\"The confusion matrix of user:\", user_id+1)\n",
        "        indexes = range(user_id*LIMIT, user_id*LIMIT+LIMIT)\n",
        "        conf_mat = confusion_matrix(true_labels[indexes], pred_labels[user_id])\n",
        "        df_cm = pd.DataFrame(conf_mat, range(10), range(10))\n",
        "        sn.set(font_scale=1.4) # for label size\n",
        "        plt.figure(figsize = (10,7))\n",
        "        sn.heatmap(df_cm, annot=True) # font size\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "6N5Lv1TEY6rG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix for domain 1 in user-independent setting"
      ],
      "metadata": {
        "collapsed": false,
        "id": "t0zeC_wwY6rG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plot_conf_mat(np.array(data1.labels), prediction1, LIMIT=100)"
      ],
      "metadata": {
        "id": "sZQSt5AaY6rH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix for domain 4 in user-independent mode"
      ],
      "metadata": {
        "collapsed": false,
        "id": "pf6ri_KoY6rH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plot_conf_mat(np.array(data4.labels), prediction4, LIMIT=100)"
      ],
      "metadata": {
        "id": "ytC9BQ9vY6rI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 :  $1 Recognizer"
      ],
      "metadata": {
        "collapsed": false,
        "id": "faWLKaWSY6rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pip install dollarpy"
      ],
      "metadata": {
        "id": "McXw4e-1Y6rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from dollarpy import Recognizer, Template, Point\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def transform(dataset):\n",
        "    result = []\n",
        "    pca_var = []\n",
        "    for user_data in dataset.data:\n",
        "        pca = PCA(n_components=2)\n",
        "        new_data = pca.fit_transform(user_data)\n",
        "        twod_data = [Point(*row) for row in new_data]\n",
        "        result.append(twod_data)\n",
        "        pca_var.append(pca.explained_variance_ratio_)\n",
        "\n",
        "    return result,pca_var\n",
        "\n",
        "final_dataset1,pca_variances1 = transform(data1)\n",
        "final_dataset4, pca_variances4 = transform(data4)\n",
        "\n",
        "print(\"The average explained variance ratio is over all the dataset 1: \", np.mean(pca_variances1, axis=0))\n",
        "print(\"The average explained variance ratio is over all the dataset 4: \", np.mean(pca_variances4, axis=0))"
      ],
      "metadata": {
        "id": "ncwyi62AY6rK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def validation(dataset, labels, LIMIT=100):\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    accuracies = []\n",
        "    predictions_per_users = []\n",
        "    for user_id in range(10):\n",
        "        indexes = range(user_id*LIMIT, user_id*LIMIT+LIMIT)\n",
        "        train_set = np.delete(dataset, indexes)\n",
        "        train_labels = np.delete(labels, indexes)\n",
        "        test_labels = labels[indexes]\n",
        "        test_set = dataset[indexes]\n",
        "        templates = []\n",
        "        for i,d in enumerate(train_set):\n",
        "            templates.append(Template(str(labels[i]), d))\n",
        "        recognizer = Recognizer(templates)\n",
        "        predictions=[]\n",
        "        for t in test_set:\n",
        "            result = recognizer.recognize(t)\n",
        "            predictions.append(result[0])\n",
        "        acc = accuracy_score(test_labels, predictions)\n",
        "        print(\"The user score {}: {}\".format(user_id+1, acc))\n",
        "        accuracies.append(acc)\n",
        "        predictions_per_users.append(predictions)\n",
        "    return accuracies, predictions_per_users\n",
        "\n",
        "def ud_validation(dataset, labels):\n",
        "    dataset = np.array(dataset)\n",
        "    labels = np.array(labels)\n",
        "    accuracies = []\n",
        "    predictions_per_samples = []\n",
        "    blocs = [[100*i + 10*k + j for i in range(10)] for j in range(10) for k in range(10)]\n",
        "    indxs = np.reshape(blocs, (10, 10, 10))\n",
        "    cnt=0\n",
        "    for b in indxs:\n",
        "        ind = b.T.flatten()\n",
        "        train_set = np.delete(dataset, ind)\n",
        "        train_labels = np.delete(labels, ind)\n",
        "        test_labels = labels[ind]\n",
        "        test_set = dataset[ind]\n",
        "        templates = []\n",
        "        for i,d in enumerate(train_set):\n",
        "            templates.append(Template(str(labels[i]), d))\n",
        "        recognizer = Recognizer(templates)\n",
        "        predictions=[]\n",
        "        for t in test_set:\n",
        "            result = recognizer.recognize(t)\n",
        "            predictions.append(result[0])\n",
        "        acc = accuracy_score(test_labels, predictions)\n",
        "        print(\"The sample score {}: {}\".format(cnt, acc))\n",
        "        accuracies.append(acc)\n",
        "        predictions_per_samples.append(predictions)\n",
        "        cnt+=1\n",
        "    return accuracies, predictions_per_samples\n"
      ],
      "metadata": {
        "id": "tJ0zOHCjY6rL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application on domain 1 User-dependent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "e3TAfwrnY6rL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "accuracies1_ud, prediction1_ud = ud_validation(final_dataset1, data1.labels)\n",
        "print(f\"Accuracies {accuracies1_ud} average accuracy {np.mean(accuracies1_ud)} and standard deviation {np.std(accuracies1_ud)}\")"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "xF1Es9y8Y6rM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application on domain 1 user-independent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "DpOtMpKRY6rM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "accuracies1, prediction1 = validation(final_dataset1, data1.labels)\n",
        "print(f\"Accuracies {accuracies1} average accuracy {np.mean(accuracies1)} and standard deviation {np.std(accuracies1)}\")"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "pyK5_NAqY6rN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application on domain 4 user-dependent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cQL5xeiqY6rN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "accuracies4_ud, prediction4_ud = ud_validation(final_dataset4, data4.labels)\n",
        "print(f\"Accuracies {accuracies4_ud} average accuracy {np.mean(accuracies4_ud)} and standard deviation {np.std(accuracies4_ud)}\")"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ONKxmKxYY6rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application on domain 4 user-independent"
      ],
      "metadata": {
        "collapsed": false,
        "id": "rT9zR_1TY6rO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "accuracies4, prediction4 = validation(final_dataset4, data4.labels)\n",
        "print(f\"Accuracies {accuracies4} average accuracy {np.mean(accuracies4)} and standard deviation {np.std(accuracies4)}\")"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "UTTcEkN-Y6rP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plot_conf_mat(np.array(data1.labels), prediction1)"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "NFa4Cav1Y6rP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plot_conf_mat(np.array(data4.labels), prediction4)"
      ],
      "metadata": {
        "id": "h7d_1JAHY6rP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(\"Model $P dollar measure from the confusion matrixes\")\n",
        "true_labels = np.array(data4.labels)\n",
        "for user_id in range(len(prediction4)):\n",
        "    indexes = range(user_id*100, user_id*100+100)\n",
        "    print(\"User \", user_id)\n",
        "    print(\"The precision\", precision_score(true_labels[indexes], prediction4[user_id], average=None))\n",
        "    print(\"The f1-score\", f1_score(true_labels[indexes], prediction4[user_id], average=None))\n",
        "    print(\"The recall\", recall_score(true_labels[indexes], prediction4[user_id], average=None))\n",
        "    print()"
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "9mcAwDTwY6rQ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}